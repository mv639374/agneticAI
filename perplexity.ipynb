{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c856f69f",
   "metadata": {},
   "source": [
    "Perfect! Let's implement **Step 1.1: Configuration & Logger Setup** with comprehensive prompt engineering notes.[1][2][3][4]\n",
    "\n",
    "***\n",
    "\n",
    "## **STEP 1.1: Configuration & Logger Setup**\n",
    "\n",
    "### **File 1: `backend/app/config.py`**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Configuration Management using Pydantic Settings v2\n",
    "\n",
    "This module centralizes all application settings using Pydantic's BaseSettings,\n",
    "which provides automatic environment variable loading, type validation, and \n",
    "structured configuration management.\n",
    "\n",
    "Key Features:\n",
    "- Automatic .env file loading\n",
    "- Type validation for all settings\n",
    "- Support for multiple LLM providers (Groq, Google Gemini)\n",
    "- Database connection management (PostgreSQL, Redis, Vector DB)\n",
    "- Security settings (API keys, JWT secrets)\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from functools import lru_cache\n",
    "from typing import Literal, Optional\n",
    "\n",
    "from pydantic import Field, PostgresDsn, RedisDsn, field_validator\n",
    "from pydantic_settings import BaseSettings, SettingsConfigDict\n",
    "\n",
    "\n",
    "class Settings(BaseSettings):\n",
    "    \"\"\"\n",
    "    Application settings loaded from environment variables.\n",
    "    \n",
    "    Pydantic automatically:\n",
    "    1. Reads from .env file\n",
    "    2. Converts environment variables to correct types\n",
    "    3. Validates required fields\n",
    "    4. Provides default values where specified\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # APPLICATION SETTINGS\n",
    "    # =========================================================================\n",
    "    APP_NAME: str = Field(\n",
    "        default=\"Autonomous Multi-Agent System\",\n",
    "        description=\"Application name for logging and monitoring\"\n",
    "    )\n",
    "    ENVIRONMENT: Literal[\"development\", \"staging\", \"production\"] = Field(\n",
    "        default=\"development\",\n",
    "        description=\"Current environment\"\n",
    "    )\n",
    "    DEBUG: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Enable debug mode (verbose logging, auto-reload)\"\n",
    "    )\n",
    "    API_HOST: str = Field(default=\"0.0.0.0\", description=\"API server host\")\n",
    "    API_PORT: int = Field(default=8000, description=\"API server port\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LLM PROVIDER SETTINGS\n",
    "    # =========================================================================\n",
    "    # We support multiple LLM providers for flexibility and cost optimization\n",
    "    # Groq: Fast inference, free tier available\n",
    "    # Google Gemini: Multimodal capabilities, generous free tier\n",
    "    \n",
    "    GROQ_API_KEY: str = Field(\n",
    "        ...,  # Required field\n",
    "        description=\"Groq API key for LLM inference\"\n",
    "    )\n",
    "    GOOGLE_API_KEY: str = Field(\n",
    "        ...,\n",
    "        description=\"Google AI Studio API key for Gemini models\"\n",
    "    )\n",
    "    \n",
    "    DEFAULT_LLM_PROVIDER: Literal[\"groq\", \"google\"] = Field(\n",
    "        default=\"groq\",\n",
    "        description=\"Default LLM provider to use\"\n",
    "    )\n",
    "    GROQ_MODEL_NAME: str = Field(\n",
    "        default=\"llama-3.3-70b-versatile\",\n",
    "        description=\"Groq model for agent reasoning\"\n",
    "    )\n",
    "    GOOGLE_MODEL_NAME: str = Field(\n",
    "        default=\"gemini-2.0-flash-exp\",\n",
    "        description=\"Google model for complex tasks\"\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # DATABASE SETTINGS (Cloud PostgreSQL)\n",
    "    # =========================================================================\n",
    "    # Using cloud PostgreSQL (Neon, Supabase, etc.) for:\n",
    "    # - Conversation history storage\n",
    "    # - LangGraph checkpointing (agent state persistence)\n",
    "    # - User management\n",
    "    \n",
    "    POSTGRES_HOST: str = Field(..., description=\"PostgreSQL host\")\n",
    "    POSTGRES_PORT: int = Field(default=5432, description=\"PostgreSQL port\")\n",
    "    POSTGRES_DB: str = Field(..., description=\"Database name\")\n",
    "    POSTGRES_USER: str = Field(..., description=\"Database user\")\n",
    "    POSTGRES_PASSWORD: str = Field(..., description=\"Database password\")\n",
    "    POSTGRES_SSL_MODE: str = Field(default=\"require\", description=\"SSL mode\")\n",
    "    \n",
    "    # Computed database URL for SQLAlchemy\n",
    "    @property\n",
    "    def DATABASE_URL(self) -> str:\n",
    "        \"\"\"\n",
    "        Constructs async PostgreSQL connection string.\n",
    "        Uses asyncpg driver for async operations with SQLAlchemy.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            f\"postgresql+asyncpg://{self.POSTGRES_USER}:{self.POSTGRES_PASSWORD}\"\n",
    "            f\"@{self.POSTGRES_HOST}:{self.POSTGRES_PORT}/{self.POSTGRES_DB}\"\n",
    "            f\"?ssl={self.POSTGRES_SSL_MODE}\"\n",
    "        )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # REDIS SETTINGS (Cloud Redis for caching)\n",
    "    # =========================================================================\n",
    "    # Redis is used for:\n",
    "    # - Agent execution state caching\n",
    "    # - Session management\n",
    "    # - Rate limiting\n",
    "    # - Hot reload mechanism (cache frequently accessed DB data)\n",
    "    \n",
    "    REDIS_HOST: str = Field(..., description=\"Redis host\")\n",
    "    REDIS_PORT: int = Field(default=6379, description=\"Redis port\")\n",
    "    REDIS_PASSWORD: Optional[str] = Field(default=None, description=\"Redis password\")\n",
    "    REDIS_DB: int = Field(default=0, description=\"Redis database number\")\n",
    "    REDIS_SSL: bool = Field(default=False, description=\"Use SSL for Redis\")\n",
    "    \n",
    "    @property\n",
    "    def REDIS_URL(self) -> str:\n",
    "        \"\"\"\n",
    "        Constructs Redis connection string.\n",
    "        Supports both redis:// and rediss:// (SSL) protocols.\n",
    "        \"\"\"\n",
    "        protocol = \"rediss\" if self.REDIS_SSL else \"redis\"\n",
    "        auth = f\"default:{self.REDIS_PASSWORD}@\" if self.REDIS_PASSWORD else \"\"\n",
    "        return f\"{protocol}://{auth}{self.REDIS_HOST}:{self.REDIS_PORT}/{self.REDIS_DB}\"\n",
    "    \n",
    "    ENABLE_CACHE: bool = Field(default=True, description=\"Enable Redis caching\")\n",
    "    CACHE_TTL: int = Field(default=3600, description=\"Cache TTL in seconds (1 hour)\")\n",
    "    CACHE_HOT_RELOAD_INTERVAL: int = Field(\n",
    "        default=300,\n",
    "        description=\"Interval to reload cache from PostgreSQL (5 minutes)\"\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # VECTOR DATABASE SETTINGS\n",
    "    # =========================================================================\n",
    "    # Vector DB is used for:\n",
    "    # - Semantic search in agent memory\n",
    "    # - Document embeddings\n",
    "    # - Conversation context retrieval\n",
    "    \n",
    "    VECTOR_DB_TYPE: Literal[\"pinecone\", \"chromadb\"] = Field(\n",
    "        default=\"pinecone\",\n",
    "        description=\"Vector database type\"\n",
    "    )\n",
    "    \n",
    "    # Pinecone settings (cloud vector DB with free tier)\n",
    "    PINECONE_API_KEY: Optional[str] = Field(default=None)\n",
    "    PINECONE_ENVIRONMENT: Optional[str] = Field(default=\"us-east-1\")\n",
    "    PINECONE_INDEX_NAME: Optional[str] = Field(default=\"agent-memory\")\n",
    "    \n",
    "    # ChromaDB settings (can be self-hosted or cloud)\n",
    "    CHROMA_HOST: Optional[str] = Field(default=\"localhost\")\n",
    "    CHROMA_PORT: Optional[int] = Field(default=8000)\n",
    "    CHROMA_COLLECTION_NAME: Optional[str] = Field(default=\"agent_embeddings\")\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SECURITY SETTINGS\n",
    "    # =========================================================================\n",
    "    API_KEY: str = Field(\n",
    "        ...,\n",
    "        min_length=32,\n",
    "        description=\"API key for authentication\"\n",
    "    )\n",
    "    SECRET_KEY: str = Field(\n",
    "        ...,\n",
    "        min_length=32,\n",
    "        description=\"JWT secret key\"\n",
    "    )\n",
    "    ALGORITHM: str = Field(default=\"HS256\", description=\"JWT algorithm\")\n",
    "    ACCESS_TOKEN_EXPIRE_MINUTES: int = Field(\n",
    "        default=30,\n",
    "        description=\"JWT token expiration time\"\n",
    "    )\n",
    "    \n",
    "    # CORS settings\n",
    "    CORS_ORIGINS: str = Field(\n",
    "        default=\"http://localhost:3000,http://127.0.0.1:3000\",\n",
    "        description=\"Comma-separated list of allowed CORS origins\"\n",
    "    )\n",
    "    \n",
    "    @property\n",
    "    def CORS_ORIGINS_LIST(self) -> list[str]:\n",
    "        \"\"\"Convert comma-separated CORS origins to list.\"\"\"\n",
    "        return [origin.strip() for origin in self.CORS_ORIGINS.split(\",\")]\n",
    "    \n",
    "    # =========================================================================\n",
    "    # AGENT CONFIGURATION\n",
    "    # =========================================================================\n",
    "    # These settings control agent behavior and LLM interaction\n",
    "    \n",
    "    MAX_AGENT_ITERATIONS: int = Field(\n",
    "        default=10,\n",
    "        description=\"Maximum iterations for agent reasoning loop\"\n",
    "    )\n",
    "    AGENT_TIMEOUT_SECONDS: int = Field(\n",
    "        default=120,\n",
    "        description=\"Timeout for agent execution (2 minutes)\"\n",
    "    )\n",
    "    ENABLE_AGENT_MEMORY: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Enable long-term memory for agents\"\n",
    "    )\n",
    "    SUPERVISOR_MODEL: str = Field(\n",
    "        default=\"llama-3.3-70b-versatile\",\n",
    "        description=\"LLM model for supervisor agent\"\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LOGGING SETTINGS\n",
    "    # =========================================================================\n",
    "    LOG_LEVEL: Literal[\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"] = Field(\n",
    "        default=\"INFO\",\n",
    "        description=\"Logging level\"\n",
    "    )\n",
    "    LOG_FORMAT: Literal[\"json\", \"console\"] = Field(\n",
    "        default=\"json\",\n",
    "        description=\"Log output format (json for production, console for dev)\"\n",
    "    )\n",
    "    ENABLE_STRUCTURED_LOGGING: bool = Field(\n",
    "        default=True,\n",
    "        description=\"Enable structlog for structured logging\"\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # PYDANTIC SETTINGS CONFIGURATION\n",
    "    # =========================================================================\n",
    "    model_config = SettingsConfigDict(\n",
    "        env_file=\".env\",  # Load from .env file\n",
    "        env_file_encoding=\"utf-8\",\n",
    "        case_sensitive=True,  # Environment variables are case-sensitive\n",
    "        extra=\"ignore\",  # Ignore extra environment variables\n",
    "    )\n",
    "\n",
    "\n",
    "@lru_cache()\n",
    "def get_settings() -> Settings:\n",
    "    \"\"\"\n",
    "    Create and cache settings instance.\n",
    "    \n",
    "    Using @lru_cache ensures settings are loaded only once and reused\n",
    "    across the application, improving performance.\n",
    "    \n",
    "    Returns:\n",
    "        Settings: Cached settings instance\n",
    "    \"\"\"\n",
    "    return Settings()\n",
    "\n",
    "\n",
    "# Export singleton instance\n",
    "settings = get_settings()\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### **File 2: `backend/app/utils/__init__.py`**\n",
    "\n",
    "```python\n",
    "\"\"\"Utility modules for the application.\"\"\"\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### **File 3: `backend/app/utils/logger.py`**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Structured Logging Setup using structlog\n",
    "\n",
    "This module configures structlog for production-grade logging with:\n",
    "- JSON output for production (easily parsed by log aggregators)\n",
    "- Human-readable console output for development\n",
    "- Request ID tracking across async operations\n",
    "- Automatic exception formatting\n",
    "- Context-aware logging (attaches metadata to all logs in request scope)\n",
    "\n",
    "Why structlog over standard logging?\n",
    "1. Structured data: Logs are key-value pairs, not just strings\n",
    "2. Context preservation: Metadata follows logs through async operations\n",
    "3. Performance: Lazy evaluation of log messages\n",
    "4. Integration: Works seamlessly with FastAPI and async code\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from typing import Any\n",
    "\n",
    "import structlog\n",
    "from structlog.types import EventDict, Processor\n",
    "\n",
    "from app.config import settings\n",
    "\n",
    "\n",
    "def drop_color_message_key(_, __, event_dict: EventDict) -> EventDict:\n",
    "    \"\"\"\n",
    "    Remove Uvicorn's color_message field from logs.\n",
    "    \n",
    "    Uvicorn duplicates messages with ANSI color codes, which we don't need\n",
    "    in structured logs.\n",
    "    \"\"\"\n",
    "    event_dict.pop(\"color_message\", None)\n",
    "    return event_dict\n",
    "\n",
    "\n",
    "def add_app_context(_, __, event_dict: EventDict) -> EventDict:\n",
    "    \"\"\"\n",
    "    Add application-level context to all logs.\n",
    "    \n",
    "    This processor automatically adds:\n",
    "    - Environment (dev/staging/prod)\n",
    "    - Application name\n",
    "    - Service version (if available)\n",
    "    \n",
    "    Useful for:\n",
    "    - Filtering logs by environment in centralized logging\n",
    "    - Identifying service in microservices architecture\n",
    "    \"\"\"\n",
    "    event_dict[\"environment\"] = settings.ENVIRONMENT\n",
    "    event_dict[\"app\"] = settings.APP_NAME\n",
    "    return event_dict\n",
    "\n",
    "\n",
    "def setup_logging() -> None:\n",
    "    \"\"\"\n",
    "    Configure structlog for the application.\n",
    "    \n",
    "    This function should be called once at application startup, before any\n",
    "    logging occurs. It configures both structlog and the standard library\n",
    "    logging to work together.\n",
    "    \n",
    "    Logging Flow:\n",
    "    1. Structlog captures log with context\n",
    "    2. Shared processors add metadata (timestamp, log level, etc.)\n",
    "    3. ProcessorFormatter wraps for standard library compatibility\n",
    "    4. Final renderer outputs JSON (prod) or console (dev)\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE SHARED PROCESSORS\n",
    "    # =========================================================================\n",
    "    # These processors run on ALL log entries, regardless of source\n",
    "    \n",
    "    timestamper = structlog.processors.TimeStamper(fmt=\"iso\")\n",
    "    \n",
    "    shared_processors: list[Processor] = [\n",
    "        # Merge context variables (request ID, user ID, etc.)\n",
    "        structlog.contextvars.merge_contextvars,\n",
    "        \n",
    "        # Add logger name (e.g., \"app.agents.supervisor\")\n",
    "        structlog.stdlib.add_logger_name,\n",
    "        \n",
    "        # Add log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
    "        structlog.stdlib.add_log_level,\n",
    "        \n",
    "        # Format positional arguments in log messages\n",
    "        structlog.stdlib.PositionalArgumentsFormatter(),\n",
    "        \n",
    "        # Add extra fields from logging.LogRecord\n",
    "        structlog.stdlib.ExtraAdder(),\n",
    "        \n",
    "        # Remove Uvicorn's duplicate color message\n",
    "        drop_color_message_key,\n",
    "        \n",
    "        # Add ISO 8601 timestamp\n",
    "        timestamper,\n",
    "        \n",
    "        # Render stack traces for exceptions\n",
    "        structlog.processors.StackInfoRenderer(),\n",
    "        \n",
    "        # Add application context\n",
    "        add_app_context,\n",
    "    ]\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE EXCEPTION FORMATTING\n",
    "    # =========================================================================\n",
    "    # For JSON logs, format exceptions as structured data\n",
    "    # For console logs, pretty-print with colors\n",
    "    \n",
    "    if settings.LOG_FORMAT == \"json\":\n",
    "        shared_processors.append(structlog.processors.format_exc_info)\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE STRUCTLOG\n",
    "    # =========================================================================\n",
    "    structlog.configure(\n",
    "        processors=shared_processors + [\n",
    "            # Final processor: wrap for standard library compatibility\n",
    "            structlog.stdlib.ProcessorFormatter.wrap_for_formatter,\n",
    "        ],\n",
    "        # Use standard library LoggerFactory for compatibility\n",
    "        logger_factory=structlog.stdlib.LoggerFactory(),\n",
    "        # Cache logger instances for performance\n",
    "        cache_logger_on_first_use=True,\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE OUTPUT RENDERER\n",
    "    # =========================================================================\n",
    "    # JSON renderer for production (machine-readable)\n",
    "    # Console renderer for development (human-readable with colors)\n",
    "    \n",
    "    log_renderer: structlog.types.Processor\n",
    "    if settings.LOG_FORMAT == \"json\":\n",
    "        log_renderer = structlog.processors.JSONRenderer()\n",
    "    else:\n",
    "        log_renderer = structlog.dev.ConsoleRenderer(\n",
    "            colors=True,  # ANSI color codes\n",
    "            exception_formatter=structlog.dev.plain_traceback,\n",
    "        )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE STANDARD LIBRARY LOGGING\n",
    "    # =========================================================================\n",
    "    # This ensures all logs (including from third-party libraries) use structlog\n",
    "    \n",
    "    formatter = structlog.stdlib.ProcessorFormatter(\n",
    "        # These run ONLY on `logging` entries that do NOT originate within structlog\n",
    "        foreign_pre_chain=shared_processors,\n",
    "        \n",
    "        # These run on ALL entries after the pre_chain\n",
    "        processors=[\n",
    "            # Remove internal structlog metadata\n",
    "            structlog.stdlib.ProcessorFormatter.remove_processors_meta,\n",
    "            \n",
    "            # Final rendering (JSON or Console)\n",
    "            log_renderer,\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # =========================================================================\n",
    "    # SETUP ROOT LOGGER\n",
    "    # =========================================================================\n",
    "    handler = logging.StreamHandler(sys.stdout)\n",
    "    handler.setFormatter(formatter)\n",
    "    \n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.addHandler(handler)\n",
    "    root_logger.setLevel(settings.LOG_LEVEL.upper())\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CONFIGURE UVICORN LOGGERS\n",
    "    # =========================================================================\n",
    "    # Uvicorn has its own loggers that need special handling\n",
    "    \n",
    "    for logger_name in [\"uvicorn\", \"uvicorn.error\"]:\n",
    "        # Clear existing handlers to avoid duplicate logs\n",
    "        uvicorn_logger = logging.getLogger(logger_name)\n",
    "        uvicorn_logger.handlers.clear()\n",
    "        \n",
    "        # Propagate to root logger (which uses our structlog formatter)\n",
    "        uvicorn_logger.propagate = True\n",
    "    \n",
    "    # Disable uvicorn.access logger (we'll log requests in middleware)\n",
    "    access_logger = logging.getLogger(\"uvicorn.access\")\n",
    "    access_logger.handlers.clear()\n",
    "    access_logger.propagate = False\n",
    "    \n",
    "    # =========================================================================\n",
    "    # LOG STARTUP MESSAGE\n",
    "    # =========================================================================\n",
    "    log = structlog.get_logger()\n",
    "    log.info(\n",
    "        \"Logging configured\",\n",
    "        log_level=settings.LOG_LEVEL,\n",
    "        log_format=settings.LOG_FORMAT,\n",
    "        structured=settings.ENABLE_STRUCTURED_LOGGING,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_logger(name: str = __name__) -> Any:\n",
    "    \"\"\"\n",
    "    Get a structlog logger instance.\n",
    "    \n",
    "    Usage:\n",
    "        from app.utils.logger import get_logger\n",
    "        \n",
    "        log = get_logger(__name__)\n",
    "        log.info(\"Processing request\", user_id=123, action=\"login\")\n",
    "    \n",
    "    Args:\n",
    "        name: Logger name (typically __name__ of the module)\n",
    "    \n",
    "    Returns:\n",
    "        Structlog logger instance\n",
    "    \"\"\"\n",
    "    return structlog.get_logger(name)\n",
    "\n",
    "\n",
    "def bind_context(**kwargs: Any) -> None:\n",
    "    \"\"\"\n",
    "    Bind context variables to the current async context.\n",
    "    \n",
    "    All subsequent logs in the same async context will include these variables.\n",
    "    \n",
    "    Usage:\n",
    "        bind_context(request_id=\"abc-123\", user_id=456)\n",
    "        log.info(\"User logged in\")  # Will include request_id and user_id\n",
    "    \n",
    "    Args:\n",
    "        **kwargs: Key-value pairs to bind to context\n",
    "    \"\"\"\n",
    "    structlog.contextvars.bind_contextvars(**kwargs)\n",
    "\n",
    "\n",
    "def clear_context() -> None:\n",
    "    \"\"\"\n",
    "    Clear all context variables from the current async context.\n",
    "    \n",
    "    Typically called at the beginning of each request to prevent context leakage.\n",
    "    \"\"\"\n",
    "    structlog.contextvars.clear_contextvars()\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "### **File 4: `backend/app/main.py`**\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "FastAPI Application Entry Point\n",
    "\n",
    "This is the main FastAPI application that:\n",
    "1. Initializes logging\n",
    "2. Configures middleware (CORS, request logging, error handling)\n",
    "3. Mounts API routes\n",
    "4. Provides health check endpoint\n",
    "\"\"\"\n",
    "\n",
    "import uuid\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "from fastapi import FastAPI, Request, status\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "\n",
    "from app.config import settings\n",
    "from app.utils.logger import bind_context, clear_context, get_logger, setup_logging\n",
    "\n",
    "# =========================================================================\n",
    "# LOGGING SETUP (must be first)\n",
    "# =========================================================================\n",
    "setup_logging()\n",
    "log = get_logger(__name__)\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# LIFESPAN CONTEXT MANAGER\n",
    "# =========================================================================\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    \"\"\"\n",
    "    Lifespan events for FastAPI application.\n",
    "    \n",
    "    This context manager handles startup and shutdown events:\n",
    "    - Startup: Initialize database connections, load models, etc.\n",
    "    - Shutdown: Close connections, cleanup resources, etc.\n",
    "    \"\"\"\n",
    "    # Startup\n",
    "    log.info(\n",
    "        \"Application starting\",\n",
    "        environment=settings.ENVIRONMENT,\n",
    "        debug=settings.DEBUG,\n",
    "    )\n",
    "    \n",
    "    # TODO: Initialize database connection pool (Step 1.2)\n",
    "    # TODO: Initialize Redis connection (Step 1.2)\n",
    "    # TODO: Initialize vector store (Step 1.2)\n",
    "    \n",
    "    yield  # Application runs here\n",
    "    \n",
    "    # Shutdown\n",
    "    log.info(\"Application shutting down\")\n",
    "    \n",
    "    # TODO: Close database connections\n",
    "    # TODO: Close Redis connection\n",
    "    # TODO: Cleanup temporary files\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# FASTAPI APP INITIALIZATION\n",
    "# =========================================================================\n",
    "app = FastAPI(\n",
    "    title=settings.APP_NAME,\n",
    "    description=\"Autonomous Multi-Agent Enterprise Intelligence System\",\n",
    "    version=\"0.1.0\",\n",
    "    docs_url=\"/docs\" if settings.DEBUG else None,  # Disable docs in production\n",
    "    redoc_url=\"/redoc\" if settings.DEBUG else None,\n",
    "    lifespan=lifespan,\n",
    ")\n",
    "\n",
    "# =========================================================================\n",
    "# MIDDLEWARE CONFIGURATION\n",
    "# =========================================================================\n",
    "\n",
    "# CORS Middleware (allows frontend to communicate with backend)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=settings.CORS_ORIGINS_LIST,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allow all HTTP methods\n",
    "    allow_headers=[\"*\"],  # Allow all headers\n",
    ")\n",
    "\n",
    "\n",
    "@app.middleware(\"http\")\n",
    "async def logging_middleware(request: Request, call_next):\n",
    "    \"\"\"\n",
    "    Request logging middleware.\n",
    "    \n",
    "    This middleware:\n",
    "    1. Generates unique request ID\n",
    "    2. Binds request context (method, path, client IP)\n",
    "    3. Logs request start and completion\n",
    "    4. Measures request duration\n",
    "    5. Clears context after request\n",
    "    \"\"\"\n",
    "    # Clear any existing context (prevents leakage between requests)\n",
    "    clear_context()\n",
    "    \n",
    "    # Generate unique request ID\n",
    "    request_id = str(uuid.uuid4())\n",
    "    \n",
    "    # Bind context for this request\n",
    "    bind_context(\n",
    "        request_id=request_id,\n",
    "        method=request.method,\n",
    "        path=request.url.path,\n",
    "        client_ip=request.client.host if request.client else \"unknown\",\n",
    "    )\n",
    "    \n",
    "    # Log request start\n",
    "    log.info(\"Request started\")\n",
    "    \n",
    "    try:\n",
    "        # Process request\n",
    "        response = await call_next(request)\n",
    "        \n",
    "        # Log request completion\n",
    "        log.info(\n",
    "            \"Request completed\",\n",
    "            status_code=response.status_code,\n",
    "        )\n",
    "        \n",
    "        # Add request ID to response headers\n",
    "        response.headers[\"X-Request-ID\"] = request_id\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    except Exception as exc:\n",
    "        log.error(\n",
    "            \"Request failed\",\n",
    "            exc_info=exc,\n",
    "            error=str(exc),\n",
    "        )\n",
    "        raise\n",
    "    \n",
    "    finally:\n",
    "        # Clear context after request\n",
    "        clear_context()\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# HEALTH CHECK ENDPOINT\n",
    "# =========================================================================\n",
    "@app.get(\n",
    "    \"/api/health\",\n",
    "    tags=[\"Health\"],\n",
    "    summary=\"Health check endpoint\",\n",
    "    response_description=\"Service health status\",\n",
    ")\n",
    "async def health_check():\n",
    "    \"\"\"\n",
    "    Health check endpoint for monitoring and load balancers.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Service status and metadata\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"environment\": settings.ENVIRONMENT,\n",
    "        \"version\": \"0.1.0\",\n",
    "    }\n",
    "\n",
    "\n",
    "@app.get(\n",
    "    \"/\",\n",
    "    tags=[\"Root\"],\n",
    "    summary=\"Root endpoint\",\n",
    ")\n",
    "async def root():\n",
    "    \"\"\"\n",
    "    Root endpoint.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Welcome message\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"message\": \"Autonomous Multi-Agent Enterprise Intelligence System\",\n",
    "        \"docs\": \"/docs\",\n",
    "        \"health\": \"/api/health\",\n",
    "    }\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# ERROR HANDLERS\n",
    "# =========================================================================\n",
    "@app.exception_handler(Exception)\n",
    "async def global_exception_handler(request: Request, exc: Exception):\n",
    "    \"\"\"\n",
    "    Global exception handler for unhandled errors.\n",
    "    \n",
    "    This catches all exceptions that aren't handled elsewhere and:\n",
    "    1. Logs the error with full context\n",
    "    2. Returns a consistent error response\n",
    "    3. Prevents sensitive information leakage\n",
    "    \"\"\"\n",
    "    log.error(\n",
    "        \"Unhandled exception\",\n",
    "        exc_info=exc,\n",
    "        error_type=type(exc).__name__,\n",
    "        error_message=str(exc),\n",
    "    )\n",
    "    \n",
    "    return JSONResponse(\n",
    "        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
    "        content={\n",
    "            \"error\": \"Internal server error\",\n",
    "            \"message\": str(exc) if settings.DEBUG else \"An unexpected error occurred\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# MOUNT ROUTERS (will be added in Step 1.5)\n",
    "# =========================================================================\n",
    "# TODO: app.include_router(agents_router, prefix=\"/api/agents\", tags=[\"Agents\"])\n",
    "# TODO: app.include_router(conversations_router, prefix=\"/api/conversations\")\n",
    "# TODO: app.include_router(websocket_router, prefix=\"/ws\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    \n",
    "    uvicorn.run(\n",
    "        \"app.main:app\",\n",
    "        host=settings.API_HOST,\n",
    "        port=settings.API_PORT,\n",
    "        reload=settings.DEBUG,\n",
    "        log_level=settings.LOG_LEVEL.lower(),\n",
    "    )\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "## **CHECKPOINT TEST: Verify Configuration & Logging**\n",
    "\n",
    "### **Commands to execute from `backend/` directory:**\n",
    "\n",
    "```bash\n",
    "# Activate virtual environment\n",
    "source .venv/bin/activate\n",
    "\n",
    "# Test configuration loading\n",
    "python -c \"from app.config import settings; print(f'✓ Config loaded: {settings.APP_NAME}')\"\n",
    "\n",
    "# Test logger setup\n",
    "python -c \"from app.utils.logger import setup_logging, get_logger; setup_logging(); log = get_logger(); log.info('Test log'); print('✓ Logger working')\"\n",
    "\n",
    "# Start FastAPI server\n",
    "uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000\n",
    "\n",
    "# In another terminal, test health endpoint\n",
    "curl http://localhost:8000/api/health\n",
    "\n",
    "# Expected output:\n",
    "# {\"status\":\"healthy\",\"environment\":\"development\",\"version\":\"0.1.0\"}\n",
    "\n",
    "# Test root endpoint\n",
    "curl http://localhost:8000/\n",
    "\n",
    "# Test with request ID tracking\n",
    "curl -v http://localhost:8000/api/health | grep -i \"x-request-id\"\n",
    "\n",
    "# View logs (should show structured JSON or colored console output)\n",
    "# Logs should include: request_id, method, path, client_ip, timestamp\n",
    "```\n",
    "\n",
    "***\n",
    "\n",
    "## **WHAT YOU'VE LEARNED**\n",
    "\n",
    "1. ✅ **Pydantic Settings**: Type-safe configuration with automatic environment variable loading\n",
    "2. ✅ **Computed Properties**: Dynamic values (DATABASE_URL, REDIS_URL, CORS_ORIGINS_LIST)\n",
    "3. ✅ **Structlog**: Structured logging with context preservation across async operations\n",
    "4. ✅ **FastAPI Lifespan**: Proper startup/shutdown handling\n",
    "5. ✅ **Middleware**: Request logging, CORS, context binding\n",
    "6. ✅ **Error Handling**: Global exception handler with structured error logging\n",
    "\n",
    "***\n",
    "\n",
    "**Reply \"done\" when your FastAPI server is running and all health checks pass, then we'll proceed to Step 1.2: Database Layer**.[2][3][4][5][1]\n",
    "\n",
    "[1](https://fastapi.tiangolo.com/advanced/settings/)\n",
    "[2](https://wazaari.dev/blog/fastapi-structlog-integration)\n",
    "[3](https://pythonic.blog/2025/02/14/pydantic-series-settings-in-a-fastapi-app/)\n",
    "[4](https://betterstack.com/community/guides/logging/structlog/)\n",
    "[5](https://www.angelospanag.me/blog/structured-logging-using-structlog-and-fastapi)\n",
    "[6](https://stackoverflow.com/questions/76674272/pydantic-basesettings-cant-find-env-when-running-commands-from-different-places)\n",
    "[7](https://docs.pydantic.dev/latest/api/pydantic_settings/)\n",
    "[8](https://github.com/abetlen/llama-cpp-python/issues/457)\n",
    "[9](https://github.com/fastapi/fastapi/discussions/9913)\n",
    "[10](https://gist.github.com/nymous/f138c7f06062b7c43c060bf03759c29e)\n",
    "[11](https://dev.to/amal/pydantic-for-fastapi-2385)\n",
    "[12](https://pypi.org/project/fastapi-structlog/)\n",
    "[13](https://docs.pydantic.dev/latest/concepts/pydantic_settings/)\n",
    "[14](https://www.dash0.com/guides/python-logging-with-structlog)\n",
    "[15](https://last9.io/blog/fastapi-python/)\n",
    "[16](https://ouassim.tech/notes/setting-up-structured-logging-in-fastapi-with-structlog/)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
